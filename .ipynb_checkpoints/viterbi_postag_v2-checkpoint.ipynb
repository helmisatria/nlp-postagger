{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import io\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read training file and create "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_init_table(fname):\n",
    "    tag_count = {}\n",
    "    tag_count['<start>'] = 0\n",
    "    word_tag = {}\n",
    "    tag_trans = {}\n",
    "    with open(fname) as f:\n",
    "        content = f.readlines()\n",
    "    # you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "    content = [x.strip() for x in content]\n",
    "    idx_line = 0\n",
    "    is_first_word = 0\n",
    "    \n",
    "    while idx_line < len(content):\n",
    "        prev_tag = '<start>'\n",
    "        while not content[idx_line].startswith('</kalimat'):\n",
    "            if  not content[idx_line].startswith('<kalimat'):\n",
    "                content_part = content[idx_line].split('\\t')\n",
    "                if content_part[1] in tag_count:\n",
    "                    tag_count[content_part[1]] += 1\n",
    "                else:\n",
    "                    tag_count[content_part[1]] = 1\n",
    "                    \n",
    "                current_word_tag = content_part[0]+','+content_part[1]\n",
    "                if current_word_tag in word_tag:\n",
    "                    word_tag[current_word_tag] += 1\n",
    "                else:    \n",
    "                    word_tag[current_word_tag] = 1\n",
    "                    \n",
    "                if is_first_word == 1:\n",
    "                    current_tag_trans = '<start>,'+content_part[1]\n",
    "                    is_first_word = 0\n",
    "                else:\n",
    "                    current_tag_trans = prev_tag+','+content_part[1]\n",
    "                    \n",
    "                if current_tag_trans in tag_trans:\n",
    "                    tag_trans[current_tag_trans] += 1\n",
    "                else:\n",
    "                    tag_trans[current_tag_trans] = 1                    \n",
    "                prev_tag = content_part[1]   \n",
    "                \n",
    "            else:\n",
    "                tag_count['<start>'] += 1\n",
    "                is_first_word = 1\n",
    "            idx_line = idx_line + 1\n",
    "\n",
    "        idx_line = idx_line+1       \n",
    "    return tag_count, word_tag, tag_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<start>': 4, 'A': 4, 'B': 2, 'F': 2, 'D': 2, 'C': 2, 'G': 2, 'E': 1}\n",
      "{'saya,A': 3, 'ingin,B': 2, 'makan,F': 1, 'ikan,D': 1, 'makan,C': 1, 'seafood,D': 1, 'kemaren,G': 1, 'dia,A': 1, 'tidur,F': 1, 'nyenyak,E': 1, 'semalam,G': 1, 'tidur,C': 1}\n",
      "{'<start>,A': 3, 'A,B': 2, 'B,F': 2, 'F,D': 1, 'A,C': 2, 'C,D': 1, 'D,G': 1, 'F,E': 1, '<start>,G': 1, 'G,A': 1}\n"
     ]
    }
   ],
   "source": [
    "tag_count, word_tag, tag_trans = read_file_init_table('sample_postagged_2.txt')\n",
    "print(tag_count)\n",
    "print(word_tag)\n",
    "print(tag_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trans_prob_table(tag_trans, tag_count):\n",
    "    print(tag_trans)\n",
    "    trans_prob = {}\n",
    "    for tag1 in tag_count.keys():\n",
    "        for tag2 in tag_count.keys():\n",
    "            #print('tag1 = ')\n",
    "            #print(tag1)\n",
    "            trans_idx = tag1+','+tag2\n",
    "            #print('trans_idx = ')\n",
    "            #print(trans_idx)\n",
    "            if trans_idx in tag_trans:\n",
    "                #print(trans_idx)\n",
    "                trans_prob[trans_idx] = tag_trans[trans_idx]/tag_count[tag1]\n",
    "    return trans_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<start>,A': 3, 'A,B': 2, 'B,F': 2, 'F,D': 1, 'A,C': 2, 'C,D': 1, 'D,G': 1, 'F,E': 1, '<start>,G': 1, 'G,A': 1}\n",
      "{'<start>,A': 0.75, '<start>,G': 0.25, 'A,B': 0.5, 'A,C': 0.5, 'B,F': 1.0, 'F,D': 0.5, 'F,E': 0.5, 'D,G': 0.5, 'C,D': 0.5, 'G,A': 0.5}\n"
     ]
    }
   ],
   "source": [
    "trans_prob = create_trans_prob_table(tag_trans, tag_count)\n",
    "print(trans_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emission_prob_table(word_tag, tag_count):\n",
    "    emission_prob = {}\n",
    "    for word_tag_entry in word_tag.keys():\n",
    "        word_tag_split = word_tag_entry.split(',')\n",
    "        current_word = word_tag_split[0]\n",
    "        current_tag = word_tag_split[1]\n",
    "        emission_key = current_word+','+current_tag\n",
    "        emission_prob[emission_key] = word_tag[word_tag_entry]/tag_count[current_tag]\n",
    "    return emission_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'saya,A': 0.75, 'ingin,B': 1.0, 'makan,F': 0.5, 'ikan,D': 0.5, 'makan,C': 0.5, 'seafood,D': 0.5, 'kemaren,G': 0.5, 'dia,A': 0.25, 'tidur,F': 0.5, 'nyenyak,E': 1.0, 'semalam,G': 0.5, 'tidur,C': 0.5}\n"
     ]
    }
   ],
   "source": [
    "emission_prob = create_emission_prob_table(word_tag, tag_count)\n",
    "print(emission_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(trans_prob, emission_prob, tag_count, sentence):\n",
    "    #initialization\n",
    "    viterbi_mat = {}\n",
    "    tag_sequence = []\n",
    "\n",
    "    sentence_words = sentence.split()\n",
    "    \n",
    "    current_tag = '<start>'\n",
    "    max_score = 1\n",
    "    for i, current_word in enumerate(sentence_words):\n",
    "        viterbi_mat[current_word] = max_score\n",
    "        scores = []\n",
    "        \n",
    "        for j, trans in enumerate(emission_prob.keys()):\n",
    "            print(trans)\n",
    "            score = 0\n",
    "            next_word = trans.split(',')[0]\n",
    "            next_tag = trans.split(',')[1]\n",
    "            \n",
    "            if (next_word == current_word):\n",
    "                print(next_word, ' ', current_word, ' ', current_tag, ' ', next_tag)\n",
    "                score = max_score * emission_prob[trans] * trans_prob[current_tag + ',' + next_tag]\n",
    "            \n",
    "            scores.append({ 'score': score, 'tag': next_tag })\n",
    "            \n",
    "        onlyScores = [x['score'] for x in scores]\n",
    "        max_index = onlyScores.index(max(onlyScores))\n",
    "        \n",
    "        current_tag = scores[max_index]['tag']\n",
    "    \n",
    "    return viterbi_mat, tag_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dia   dia   A   A\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'A,A'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-101feb8a3494>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"<start> dia ingin makan kemaren\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult_viterbi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mviterbi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memission_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_viterbi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-727a5b96b99b>\u001b[0m in \u001b[0;36mviterbi\u001b[0;34m(trans_prob, emission_prob, tag_count, sentence)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnext_word\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcurrent_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_score\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0memission_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtrans_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_tag\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m','\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnext_tag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m \u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tag'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnext_tag\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'A,A'"
     ]
    }
   ],
   "source": [
    "sentence = \"<start> dia ingin makan kemaren\"\n",
    "result_viterbi = viterbi(trans_prob, emission_prob, tag_count, sentence)\n",
    "print(result_viterbi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
